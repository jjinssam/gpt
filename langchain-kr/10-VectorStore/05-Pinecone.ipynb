{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone\n",
    "\n",
    "Pinecone은 고성능 벡터 데이터베이스로, AI 및 머신러닝 애플리케이션을 위한 효율적인 벡터 저장 및 검색 솔루션입니다. \n",
    "\n",
    "**주요 특징:**\n",
    "\n",
    "1. 벡터 데이터 저장 및 검색: 고차원 벡터 데이터를 효율적으로 저장하고 검색할 수 있는 시스템을 제공합니다.\n",
    "\n",
    "2. 확장성: 대규모 데이터셋을 처리할 수 있는 확장 가능한 아키텍처를 갖추고 있습니다.\n",
    "\n",
    "3. 개발자 친화적: API를 통해 쉽게 사용할 수 있으며, 다양한 AI 모델과 호환됩니다.\n",
    "\n",
    "4. 완전 관리형 서비스: 사용자가 인프라 관리에 신경 쓰지 않고 애플리케이션 개발에 집중할 수 있습니다.\n",
    "\n",
    "**주요 장점:**\n",
    "\n",
    "1. 고성능 검색: 수십억 개의 아이템을 밀리초 단위로 빠르게 검색할 수 있습니다.\n",
    "\n",
    "2. AI 애플리케이션 강화: 관련 정보 검색에 의존하는 AI 애플리케이션의 성능을 향상시킬 수 있습니다.\n",
    "\n",
    "3. 쉬운 시작 및 확장: 몇 번의 클릭이나 API 호출만으로 계정 생성과 인덱스 설정이 가능합니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [Pinecone 공식 홈페이지](https://docs.pinecone.io/integrations/langchain)\n",
    "- [Pinecone 랭체인](https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주석 해제 후 설치\n",
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 불용어 사전 가져오기 (추후 토크나이저에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아',\n",
       " '휴',\n",
       " '아이구',\n",
       " '아이쿠',\n",
       " '아이고',\n",
       " '어',\n",
       " '나',\n",
       " '우리',\n",
       " '저희',\n",
       " '따라',\n",
       " '의해',\n",
       " '을',\n",
       " '를',\n",
       " '에',\n",
       " '의',\n",
       " '가',\n",
       " '으로',\n",
       " '로',\n",
       " '에게',\n",
       " '뿐이다']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.korean import stopwords\n",
    "\n",
    "# 한글 불용어 사전 불러오기 (불용어 사전 출처: https://www.ranks.nl/stopwords/korean)\n",
    "stopwords()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "아래는 일반 문서의 전처리 과정입니다. `ROOT_DIR` 하위에 있는 모든 `.pdf` 파일을 읽어와 `document_lsit` 에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "ROOT_DIR = \"./data\"\n",
    "files = glob.glob(ROOT_DIR + \"/*.pdf\")\n",
    "\n",
    "document_list = []\n",
    "for file in files:\n",
    "    docs = PyMuPDFLoader(file).load()\n",
    "    document_list.extend(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk 크기로 나눈 뒤, 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=350, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(document_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone 에 DB 저장하기 위한 문서 전처리를 수행합니다. 이 과정에서 `metadata_keys` 를 지정할 수 있습니다.\n",
    "\n",
    "추가로 metadata 를 태깅하고 싶은 경우 사전 처리 작업에서 미리 metadata 를 추가한 뒤 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import preprocess_documents\n",
    "\n",
    "contents, metadatas = preprocess_documents(\n",
    "    split_docs=split_docs, metadata_keys=[\"source\", \"page\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinecone: 인덱스 생성\n",
    "\n",
    "파인콘의 새로운 인덱스를 생성합니다.\n",
    "\n",
    "![pinecone-01.png](./images/pinecone-01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[create_index]\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 0}},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.community.pinecone import create_index\n",
    "\n",
    "pc_index = create_index(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    index_name=\"teddynote-db-index\",  # 인덱스 이름을 지정합니다.\n",
    "    dimension=4096,  # Embedding 차원과 맞춥니다. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "    metric=\"dotproduct\",  # 유사도 측정 방법을 지정합니다. (dotproduct, euclidean, cosine)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Encoder 를 생성합니다. 여기서는 Kiwi 토크나이저를 사용한 Sparse Encoder 를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import (\n",
    "    create_sparse_encoder,\n",
    "    fit_save_sparse_encoder,\n",
    ")\n",
    "\n",
    "# 한글 불용어 사전 + Kiwi 형태소 분석기를 사용합니다.\n",
    "sparse_encoder = create_sparse_encoder(stopwords(), mode=\"kiwi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Encoder 에 Corpus 를 학습합니다.\n",
    "\n",
    "- `save_path`: Sparse Encoder 를 저장할 경로입니다. 추후에 `pickle` 형식으로 저장한 Sparse Encoder 를 불러와 Query 임베딩할 때 사용합니다. 따라서, 이를 저장할 경로를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c0dee6bd124335815748f9d2e9a592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fit_save_sparse_encoder] Saved sparse encoder to ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sparse Encoder 를 학습합니다.\n",
    "# 저장하는 경로(save_path)를 잘 기억합니다.\n",
    "saved_path = fit_save_sparse_encoder(\n",
    "    sparse_encoder=sparse_encoder, contents=contents, save_path=\"./sparse_encoder.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[선택사항] 아래는 나중에 학습하고 저장한 Sparse Encoder 를 다시 불러와야 할 때 사용하는 코드입니다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import load_sparse_encoder\n",
    "\n",
    "# 추후에 학습된 sparse encoder 를 불러올 때 사용합니다.\n",
    "sparse_encoder = load_sparse_encoder(\"./sparse_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone: DB Index에 추가 (Upsert)\n",
    "\n",
    "![](./images/pinecone-02.png)\n",
    "\n",
    "- `context`: 문서의 내용입니다.\n",
    "- `page`: 문서의 페이지 번호입니다.\n",
    "- `source`: 문서의 출처입니다.\n",
    "- `values`: Embedder 를 통해 얻은 문서의 임베딩입니다.\n",
    "- `sparse values`: Sparse Encoder 를 통해 얻은 문서의 임베딩입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2a8734a6524a16b037b8e73eda52eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[upsert_documents]\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'teddynote-namespace-01': {'vector_count': 160}},\n",
      " 'total_vector_count': 160}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import upsert_documents\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "\n",
    "upsert_documents(\n",
    "    index=pc_index,  # Pinecone 인덱스\n",
    "    namespace=\"teddynote-namespace-01\",  # Pinecone namespace\n",
    "    contents=contents,  # 이전에 전처리한 문서 내용\n",
    "    metadatas=metadatas,  # 이전에 전처리한 문서 메타데이터\n",
    "    sparse_encoder=sparse_encoder,  # Sparse encoder\n",
    "    embedder=UpstageEmbeddings(\n",
    "        model=\"solar-embedding-1-large-passage\"\n",
    "    ),  # Dense Embedder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init_pinecone_index]\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'teddynote-namespace-01': {'vector_count': 160}},\n",
      " 'total_vector_count': 160}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import init_pinecone_index\n",
    "\n",
    "pinecone_params = init_pinecone_index(\n",
    "    index_name=\"teddynote-db-index\",  # Pinecone 인덱스 이름\n",
    "    namespace=\"teddynote-namespace-01\",  # Pinecone Namespace\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],  # Pinecone API Key\n",
    "    sparse_encoder_pkl_path=\"./sparse_encoder.pkl\",  # Sparse Encoder 저장경로(save_path)\n",
    "    stopwords=stopwords(),  # 불용어 사전\n",
    "    tokenizer=\"kiwi\",\n",
    "    embeddings=UpstageEmbeddings(\n",
    "        model=\"solar-embedding-1-large-query\"\n",
    "    ),  # Dense Embedder\n",
    "    top_k=3,  # Top-K 문서 반환 개수\n",
    "    alpha=0.5,  # alpha=0.75로 설정한 경우, (0.75: Dense Embedding, 0.25: Sparse Embedding)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PineconeKiwiHybridRetriever` 를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
    "\n",
    "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace teddynote-namespace-01\n",
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 \n",
      "n 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은 \n",
      "구글과 클라우드 서비스 사용 계약도 체결\n",
      "n 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인 \n",
      "앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "KEY Contents\n",
      "£ 구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\n",
      "n 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\n",
      "{'source': './data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 13.0, 'score': 0.56979203}\n",
      "\n",
      "====================\n",
      "\n",
      "달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\n",
      "∙구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월 \n",
      "앤스로픽에 최대 40억 달러의 투자 계획을 공개\n",
      "∙한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해 \n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei) \n",
      "남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\n",
      "{'source': './data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 13.0, 'score': 0.46733376}\n",
      "\n",
      "====================\n",
      "\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································ 9\n",
      "   ▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\n",
      "   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\n",
      "{'source': './data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1.0, 'score': 0.42080107}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\"앤스로픽\")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seoulrnd-graphrag-gR8UbrDn-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
